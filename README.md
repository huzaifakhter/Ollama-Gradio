# Ollama&Gradio
Run **Ollama LLMs in the Browser** using **Gradio**

## Features  
Run **Llama 3.2** or any **Ollama** model  
**Gradio UI** for easy interaction  
Lightweight & simple setup  
Saves the history in json format, then reloads it when app runs again.

## Installation  
Make sure you have downloaded Ollama; if not, <a href="https://ollama.com/download" target="_blank">Visit Here</a>  

After the download is complete, download any model example: llama3.2:1b, run: `ollama run llama3.2:1b`

## Python Libraries
You have to install Gradio and Ollama from pip, run: 
`pip install gradio ollama`

## Run App
After all the requirements are satisfied, run the app
`python3 app.py`
Visit the localhost url, that is provided in CLI.

## Message
Keep Calm And Code On.


